7.0s 1 0.00s - Debugger warning: It seems that frozen modules are being used, which may
7.0s 2 0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off
7.0s 3 0.00s - to python to disable frozen modules.
7.0s 4 0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.
7.5s 5 0.00s - Debugger warning: It seems that frozen modules are being used, which may
7.5s 6 0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off
7.5s 7 0.00s - to python to disable frozen modules.
7.5s 8 0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.
14.0s 9 Device used: cuda
15.0s 10 Count of mode: 85.20 Million87
19.3s 11 Training Starts
19.3s 12 
22.2s 13 Step 0: Loss 4.3495
272.4s 14 Step 100: Loss 3.2976
528.2s 15 Step 200: Loss 3.3214
783.9s 16 Step 300: Loss 3.3027
1039.2s 17 Step 400: Loss 3.3144
1294.3s 18 Step 500: Loss 3.2987
1550.2s 19 Step 600: Loss 3.2294
1806.7s 20 Step 700: Loss 2.8686
2063.2s 21 Step 800: Loss 2.5932
2320.0s 22 Step 900: Loss 2.4221
2576.9s 23 Step 1000: Loss 2.2490
2834.1s 24 Step 1100: Loss 2.1729
3091.2s 25 Step 1200: Loss 1.9879
3348.2s 26 Step 1300: Loss 1.8811
3605.5s 27 Step 1400: Loss 1.7549
3863.1s 28 Step 1500: Loss 1.6415
4120.9s 29 Step 1600: Loss 1.5423
4378.5s 30 Step 1700: Loss 1.4624
4636.0s 31 Step 1800: Loss 1.3766
4893.4s 32 Step 1900: Loss 1.3696
5150.9s 33 Step 2000: Loss 1.3540
5408.6s 34 Step 2100: Loss 1.2979
5666.6s 35 Step 2200: Loss 1.2791
5924.0s 36 Step 2300: Loss 1.2411
6181.2s 37 Step 2400: Loss 1.2245
6438.5s 38 Step 2500: Loss 1.1778
6695.7s 39 Step 2600: Loss 1.1740
6953.0s 40 Step 2700: Loss 1.1125
7210.4s 41 Step 2800: Loss 1.0817
7468.2s 42 Step 2900: Loss 1.0565
7726.0s 43 Step 3000: Loss 1.0275
7983.4s 44 Step 3100: Loss 0.9966
8241.1s 45 Step 3200: Loss 0.9570
8499.1s 46 Step 3300: Loss 0.9062
8757.0s 47 Step 3400: Loss 0.8749
9014.9s 48 Step 3500: Loss 0.8313
9272.8s 49 Step 3600: Loss 0.8108
9530.6s 50 Step 3700: Loss 0.7672
9788.0s 51 Step 3800: Loss 0.7196
10045.6s 52 Step 3900: Loss 0.6872
10303.6s 53 Step 4000: Loss 0.6406
10561.4s 54 Step 4100: Loss 0.6281
10819.5s 55 Step 4200: Loss 0.5770
11077.5s 56 Step 4300: Loss 0.5381
11335.5s 57 Step 4400: Loss 0.5178
11593.3s 58 Step 4500: Loss 0.4895
11850.9s 59 Step 4600: Loss 0.4326
12109.4s 60 Step 4700: Loss 0.4105
12367.8s 61 Step 4800: Loss 0.3974
12625.8s 62 Step 4900: Loss 0.3935
12883.7s 63 Step 5000: Loss 0.3639
13141.4s 64 Step 5100: Loss 0.3417
13399.3s 65 Step 5200: Loss 0.3242
13657.5s 66 Step 5300: Loss 0.3185
13915.4s 67 Step 5400: Loss 0.3023
14173.3s 68 Step 5500: Loss 0.2964
14431.3s 69 Step 5600: Loss 0.2928
14689.2s 70 Step 5700: Loss 0.2802
14947.1s 71 Step 5800: Loss 0.2695
15205.6s 72 Step 5900: Loss 0.2566
15463.3s 73 Step 6000: Loss 0.2654
15721.6s 74 Step 6100: Loss 0.2531
15979.3s 75 Step 6200: Loss 0.2458
16237.7s 76 Step 6300: Loss 0.2370
16495.5s 77 Step 6400: Loss 0.2318
16754.1s 78 Step 6500: Loss 0.2320
17011.5s 79 Step 6600: Loss 0.2258
17269.5s 80 Step 6700: Loss 0.2291
17528.1s 81 Step 6800: Loss 0.2225
17786.3s 82 Step 6900: Loss 0.2175
18044.5s 83 Step 7000: Loss 0.2181
18303.0s 84 Step 7100: Loss 0.2184
18560.9s 85 Step 7200: Loss 0.2103
18818.6s 86 Step 7300: Loss 0.2078
19076.5s 87 Step 7400: Loss 0.2101
19334.1s 88 Step 7500: Loss 0.2047
19591.8s 89 Step 7600: Loss 0.2060
19849.8s 90 Step 7700: Loss 0.2058
20108.3s 91 Step 7800: Loss 0.1943
20366.5s 92 Step 7900: Loss 0.1955
20624.6s 93 Step 8000: Loss 0.1898
20882.5s 94 Step 8100: Loss 0.1902
21140.3s 95 Step 8200: Loss 0.1908
21398.3s 96 Step 8300: Loss 0.1886
21656.2s 97 Step 8400: Loss 0.1963
21914.6s 98 Step 8500: Loss 0.1821
22173.2s 99 Step 8600: Loss 0.1866
22431.8s 100 Step 8700: Loss 0.1831
22687.6s 101 Step 8800: Loss 0.1956
22945.7s 102 Step 8900: Loss 0.1885
23204.1s 103 Step 9000: Loss 0.1843
23462.0s 104 Step 9100: Loss 0.1799
23720.4s 105 Step 9200: Loss 0.1745
23979.0s 106 Step 9300: Loss 0.1769
24237.5s 107 Step 9400: Loss 0.1791
24496.0s 108 Step 9500: Loss 0.1771
24754.2s 109 Step 9600: Loss 0.1803
25012.0s 110 Step 9700: Loss 0.1783
25270.3s 111 Step 9800: Loss 0.1679
25527.7s 112 Step 9900: Loss 0.1762
25783.0s 113 Training Finished. Final Loss: 0.1707
25783.0s 114 
25783.0s 115 --- Inference ---
25787.4s 116 O God, O God! that e'er this tongue of mine,
25787.4s 117 That laid the sentence of dread banishment
25787.4s 118 On yon proud man, should take it off again
25787.4s 119 With words of sooth! O that I were as great
25787.4s 120 As is my grief, or lesser than my name!
25787.4s 121 Or that I could forget what I have been,
25787.4s 122 Or not remember what I must be now!
25787.4s 123 Swell'st thou, proud heart? I'll give thee scope to beat,
25787.4s 124 Since foes have scope to beat both thee and me.
25787.4s 125 
25787.4s 126 DUKE OF AUMERLE:
25787.4s 127 Northumberland comes back from Bolingbroke.
25787.4s 128 
25787.4s 129 SICINIUS:
25787.4s 130 Pardon me, Marcius!
25787.4s 131 
25787.4s 132 BRUTUS:
25787.4s 133 He has no equ
25791.7s 134 /usr/local/lib/python3.11/dist-packages/traitlets/traitlets.py:2915: FutureWarning: --Exporter.preprocessors=["remove_papermill_header.RemovePapermillHeader"] for containers is deprecated in traitlets 5.0. You can pass `--Exporter.preprocessors item` ... multiple times to add items to a list.
25791.7s 135 warn(
25791.7s 136 [NbConvertApp] Converting notebook __notebook__.ipynb to notebook
25792.0s 137 [NbConvertApp] Writing 31059 bytes to __notebook__.ipynb
25794.4s 138 /usr/local/lib/python3.11/dist-packages/traitlets/traitlets.py:2915: FutureWarning: --Exporter.preprocessors=["nbconvert.preprocessors.ExtractOutputPreprocessor"] for containers is deprecated in traitlets 5.0. You can pass `--Exporter.preprocessors item` ... multiple times to add items to a list.
25794.4s 139 warn(
25794.4s 140 [NbConvertApp] Converting notebook __notebook__.ipynb to html
25795.1s 141 [NbConvertApp] Writing 336266 bytes to __results__.html